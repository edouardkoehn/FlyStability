{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook that generates the plot for the training of random model with learning through synpatic weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flybrain.utils as utils\n",
    "import flybrain.model as model\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_experiments(nSamples:int,\n",
    "                     subfolder:str, \n",
    "                     activation:str, \n",
    "                     weights=True, \n",
    "                     shifts=False, \n",
    "                     gains=False,\n",
    "                     N=100,\n",
    "                     Nle=1,\n",
    "                     Epochs=400,\n",
    "                     lr=0.01 ,\n",
    "                     loss='MSE',\n",
    "                     target='0.00',\n",
    "                     g=1.0,\n",
    "                     tons=0.2,\n",
    "                     tsim=200,\n",
    "                     dt=0.1):\n",
    "    data=[]\n",
    "    gen_path=os.path.join(utils.get_root(), 'data', 'logs',subfolder,'weigth') \n",
    "    if loss=='Entropy':\n",
    "        model_path=f\"{activation}_Weights{weights}_Shifts{shifts}_Gains{gains}_N{N}_lr{lr}_NLE{Nle}_Epochs{Epochs}_{loss}_g{g}_Tons{tons}_Tsim{tsim}_dt{dt}\"\n",
    "    \n",
    "    else:\n",
    "        model_path=f\"{activation}_Weights{weights}_Shifts{shifts}_Gains{gains}_N{N}_lr{lr}_NLE{Nle}_Epochs{Epochs}_{loss}_{target}_g{g}_Tons{tons}_Tsim{tsim}_dt{dt}\"\n",
    "    for i in range(nSamples):\n",
    "        path=os.path.join(gen_path, model_path +f\"_Sample{i}_logs.json\")\n",
    "        data.append(utils.load_logs(file_path=path))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Load the runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tanhpos_n100_nle1=load_experiments(nSamples=5,subfolder='rd_rnn',activation='tanh_positive', Nle=1)\n",
    "tanhpos_n100_nle10=load_experiments(nSamples=5,subfolder='rd_rnn',activation='tanh_positive', Nle=10)\n",
    "tanhpos_n100_nle25=load_experiments(nSamples=5,subfolder='rd_rnn',activation='tanh_positive', Nle=25)\n",
    "tanhpos_n100_nle50=load_experiments(nSamples=5,subfolder='rd_rnn',activation='tanh_positive', Nle=50)\n",
    "tanhpos_n100_nle75=load_experiments(nSamples=5,subfolder='rd_rnn',activation='tanh_positive', Nle=75)\n",
    "tanhpos_n100_nle100=load_experiments(nSamples=5,subfolder='rd_rnn',activation='tanh_positive', Nle=100)\n",
    "exp_nle=[tanhpos_n100_nle1,\n",
    "         tanhpos_n100_nle10,\n",
    "         tanhpos_n100_nle25,\n",
    "         tanhpos_n100_nle50,\n",
    "         tanhpos_n100_nle75,\n",
    "         tanhpos_n100_nle100]\n",
    "\n",
    "tanhpos_n25_nle2=load_experiments(N=25,nSamples=5,subfolder='rd_rnn',activation='tanh_positive', Nle=2)\n",
    "tanhpos_n50_nle5=load_experiments(N=50,nSamples=5,subfolder='rd_rnn',activation='tanh_positive', Nle=5)\n",
    "tanhpos_n100_nle10=load_experiments(N=100,nSamples=5,subfolder='rd_rnn',activation='tanh_positive', Nle=10)\n",
    "tanhpos_n200_nle20=load_experiments(N=200,nSamples=5,subfolder='rd_rnn',activation='tanh_positive', Nle=20)\n",
    "tanhpos_n400_nle40=load_experiments(N=400,nSamples=5,subfolder='rd_rnn',activation='tanh_positive', Nle=40)\n",
    "tanhpos_n500_nle50=load_experiments(N=500,nSamples=5,subfolder='rd_rnn',activation='tanh_positive', Nle=50)\n",
    "exp_n=[tanhpos_n25_nle2,\n",
    "         tanhpos_n50_nle5,\n",
    "         tanhpos_n100_nle10,\n",
    "         tanhpos_n200_nle20,\n",
    "         tanhpos_n400_nle40,\n",
    "         tanhpos_n500_nle50\n",
    "        ]\n",
    "         \n",
    "tanhpos_n50_nle5_100=load_experiments(N=50,nSamples=5,subfolder='rd_rnn',activation='tanh_positive', Nle=5, target=\"100.00\")            \n",
    "tanhpos_n100_nle10_Exploding=load_experiments(N=100,nSamples=3,subfolder='rd_rnn',activation='tanh_positive', Nle=10, target=\"2.00\")       \n",
    "tanhpos_n100_nle10_Vanishing=load_experiments(N=100,nSamples=3,subfolder='rd_rnn',activation='tanh_positive', Nle=10, target=\"-2.00\")  \n",
    "tanhpos_n100_nle10_custom=load_experiments(N=100,nSamples=3,subfolder='rd_rnn',activation='tanh_positive', Nle=10, target=\"1.25_-1.25\") \n",
    "\n",
    "tanhpos_n100_nle10_custom_01=load_experiments(N=100,nSamples=3,subfolder='rd_rnn',activation='tanh_positive', Nle=10, target=\"1.25_-1.25\", lr=0.1) \n",
    "\n",
    "tanhpos_n100_nle10_10=load_experiments(N=100,nSamples=3,subfolder='rd_rnn',activation='tanh_positive', Nle=10, target=\"10.00\", lr=0.01, Epochs=300) \n",
    "\n",
    "grad_exp=[tanhpos_n50_nle5_100,tanhpos_n100_nle10_Exploding,tanhpos_n100_nle10_Vanishing]     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Plot the training logs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_logs_trainings(list_of_logs, \n",
    "                        entry_used, \n",
    "                        axs,\n",
    "                        serie, \n",
    "                        color):\n",
    "    data=np.zeros((len(list_of_logs),len(list_of_logs[0][entry_used])))\n",
    "    for i, sample in enumerate(list_of_logs):\n",
    "        run = np.array(sample[entry_used])\n",
    "        axs.plot(np.arange(len(run)),run, alpha=0.2, color=color, lw=1)\n",
    "    \n",
    "    # Assign the processed run to the data matrix\n",
    "        data[i, :] = run\n",
    "    mean=np.nanmean(data[:,:-1], axis=0 )\n",
    "    var=np.nanstd(data[:,:-1], axis=0)\n",
    "    epochs=np.arange(len(mean))\n",
    "    \n",
    "    axs.plot(epochs, mean,label=f'{serie}' ,alpha=0.9, lw=2,color=color)\n",
    "    #axs.fill_between(epochs,mean-var,mean+var,alpha=0.1\n",
    "                    #marker=\"D\",\n",
    "                    #markersize=1,\n",
    "                    #linewidth=0.5,label=fr'$T_{\"on\"}:{tON}$'\n",
    "    #                )\n",
    "    #axs.legend()\n",
    "    return\n",
    "\n",
    "def plot_logs_spectrums(list_of_logs, \n",
    "                        entry_used, \n",
    "                        axs,\n",
    "                        serie, \n",
    "                        color):\n",
    "    data=np.zeros((len(list_of_logs),len(list_of_logs[0][entry_used])))\n",
    "    for i, sample in enumerate(list_of_logs):\n",
    "        run = np.array(sample[entry_used])\n",
    "        axs.plot(np.linspace(0,100, len(run)),run, alpha=0.2, color=color, lw=1)\n",
    "    \n",
    "    # Assign the processed run to the data matrix\n",
    "        data[i, :] = run\n",
    "    mean=np.nanmean(data[:,:-1], axis=0 )\n",
    "    var=np.nanstd(data[:,:-1], axis=0)\n",
    "    epochs=np.linspace(0,100, len(mean))\n",
    "    \n",
    "    axs.plot(epochs, mean,label=f'{serie}' ,alpha=0.9, lw=2,color=color, marker='o', markersize=2)\n",
    "    #axs.fill_between(epochs,mean-var,mean+var,alpha=0.1\n",
    "                    #marker=\"D\",\n",
    "                    #markersize=1,\n",
    "                    #linewidth=0.5,label=fr'$T_{\"on\"}:{tON}$'\n",
    "    #                )\n",
    "    axs.legend()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Experiment number of exponent used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss vs Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs=plt.subplots(1,1, figsize=(7,5),sharex=True)\n",
    "axs.spines[\"right\"].set_color(\"none\")\n",
    "axs.spines[\"top\"].set_color(\"none\")\n",
    "\n",
    "plot_logs_trainings(tanhpos_n100_nle1,'training_loss', axs, 'NLE:1', color='blue')\n",
    "plot_logs_trainings(tanhpos_n100_nle10,'training_loss', axs, 'NLE:10', color='orange')\n",
    "plot_logs_trainings(tanhpos_n100_nle25,'training_loss', axs, 'NLE:25', color='red')\n",
    "plot_logs_trainings(tanhpos_n100_nle50,'training_loss', axs, 'NLE:50', color='green')\n",
    "plot_logs_trainings(tanhpos_n100_nle75,'training_loss', axs, 'NLE:75', color='gray')\n",
    "#plot_logs_trainings(tanhpos_n100_nle100,'training_loss', axs, 'NLE:100', color='pink')\n",
    "\n",
    "axs.set_xlim([0,80])\n",
    "#axs.set_yscale('log')\n",
    "axs.set_ylabel(r\"$|L(\\hat \\lambda_{\\theta})|$\",fontsize=20)\n",
    "axs.set_xlabel(r\"$epochs$\",fontsize=14)\n",
    "axs.tick_params(axis='both', which='major', labelsize=16)\n",
    "axs.legend(fontsize=20, frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/fig/FINAL/1_RD_Weights_NLE_trainingloss.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lambda max vs Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs=plt.subplots(1,1, figsize=(7,5),sharex=True)\n",
    "axs.spines[\"right\"].set_color(\"none\")\n",
    "axs.spines[\"top\"].set_color(\"none\")\n",
    "\n",
    "plot_logs_trainings(tanhpos_n100_nle1,'training_loss', axs, 'NLE:1', color='blue')\n",
    "plot_logs_trainings(tanhpos_n100_nle10,'training_lambda_max', axs, 'NLE:10', color='orange')\n",
    "plot_logs_trainings(tanhpos_n100_nle25,'training_lambda_max', axs, 'NLE:25', color='red')\n",
    "plot_logs_trainings(tanhpos_n100_nle50,'training_lambda_max', axs, 'NLE:50', color='green')\n",
    "plot_logs_trainings(tanhpos_n100_nle75,'training_lambda_max', axs, 'NLE:75', color='gray')\n",
    "#plot_logs_trainings(tanhpos_n100_nle100,'training_loss', axs, 'NLE:100', color='pink')\n",
    "\n",
    "\n",
    "axs.set_xlim([0,80])\n",
    "axs.hlines(y=0,xmin=0, xmax=100, ls='--', color='black' ,lw=2)\n",
    "axs.set_ylabel(r\"$\\lambda{max}$\",fontsize=20)\n",
    "axs.set_xlabel(r\"$epochs$\",fontsize=20)\n",
    "axs.tick_params(axis='both', which='major', labelsize=16)\n",
    "axs.legend(fontsize=20, frameon=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/fig/FINAL/1_RD_Weights_NLE_lambdaMax_evolution.svg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs=plt.subplots(1,1, figsize=(7,5),sharex=True)\n",
    "axs.spines[\"right\"].set_color(\"none\")\n",
    "axs.spines[\"top\"].set_color(\"none\")\n",
    "\n",
    "plot_logs_trainings(tanhpos_n100_nle1,'spectrum', axs, 'NLE:1', color='blue')\n",
    "plot_logs_trainings(tanhpos_n100_nle10,'spectrum', axs, 'NLE:10', color='orange')\n",
    "plot_logs_trainings(tanhpos_n100_nle25,'spectrum', axs, 'NLE:25', color='red')\n",
    "plot_logs_trainings(tanhpos_n100_nle50,'spectrum', axs, 'NLE:50', color='green')\n",
    "plot_logs_trainings(tanhpos_n100_nle75,'spectrum', axs, 'NLE:75', color='gray')\n",
    "#plot_logs_trainings(tanhpos_n100_nle100,'training_loss', axs, 'NLE:100', color='pink')\n",
    "\n",
    "axs.set_xlim([0,100])\n",
    "axs.hlines(y=0,xmin=0, xmax=100, ls='--', color='black' ,lw=2, alpha=0.5)\n",
    "axs.set_ylabel(r\"$\\lambda_{i}$\",fontsize=20)\n",
    "axs.set_xlabel(r\"$i$\",fontsize=20)\n",
    "axs.tick_params(axis='both', which='major', labelsize=16)\n",
    "axs.legend(loc='lower left',fontsize=19, frameon=False)\n",
    "#axs.set_ylim(-4,1)\n",
    "axs.set_ylim(-4,1)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/fig/FINAL/1_RD_Weights_NLE_spectrum.svg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Experiment Network size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs=plt.subplots(1,1, figsize=(7,5),sharex=True)\n",
    "axs.spines[\"right\"].set_color(\"none\")\n",
    "axs.spines[\"top\"].set_color(\"none\")\n",
    "\n",
    "plot_logs_spectrums(tanhpos_n25_nle2,'spectrum', axs, 'N:25', color='blue')\n",
    "plot_logs_spectrums(tanhpos_n50_nle5,'spectrum', axs, 'N:50', color='orange')\n",
    "plot_logs_spectrums(tanhpos_n100_nle100,'spectrum', axs, 'N:100', color='red')\n",
    "plot_logs_spectrums(tanhpos_n200_nle20,'spectrum', axs, 'N:200', color='green')\n",
    "plot_logs_spectrums(tanhpos_n400_nle40,'spectrum', axs, 'N:400', color='pink')\n",
    "plot_logs_spectrums(tanhpos_n500_nle50,'spectrum', axs, 'N:500', color='gray')\n",
    "\n",
    "axs.set_xlim([0,100])\n",
    "axs.hlines(y=0,xmin=0, xmax=100, ls='--', color='black' ,lw=2, alpha=0.5)\n",
    "axs.set_ylabel(r\"$\\lambda_{i}$\",fontsize=22)\n",
    "axs.set_xlabel(r\"$i$\",fontsize=22)\n",
    "axs.tick_params(axis='both', which='major', labelsize=16)\n",
    "#axs.legend(loc='lower left',fontsize=20, frameon=False)\n",
    "axs.set_ylim(-2,1) \n",
    "\n",
    "#axs.set_xlim([0,52]) \n",
    "plt.tight_layout()\n",
    "#plt.savefig('../data/fig/FINAL/1_RD_Weights_NetworkSize_Effi.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Experiment MinMax spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss vs epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grad analysis\n",
    "fig, axs=plt.subplots(1,1, figsize=(7,5),sharex=True)\n",
    "axs.spines[\"right\"].set_color(\"none\")\n",
    "axs.spines[\"top\"].set_color(\"none\")\n",
    "\n",
    "plot_logs_trainings(tanhpos_n100_nle10_Exploding,'grad_weights', axs, r'$\\lambda_{target}:2$', color='green')\n",
    "plot_logs_trainings(tanhpos_n100_nle10,'grad_weights', axs, r'$\\lambda_{target}:0$', color='red')\n",
    "plot_logs_trainings(tanhpos_n100_nle10_Vanishing,'grad_weights', axs, r'$\\lambda_{target};:-2$', color='blue')\n",
    "\n",
    "\n",
    "\n",
    "#axs.set_xlim([0,80])\n",
    "#axs.set_ylim([0,10])\n",
    "axs.set_xlim([0,250])\n",
    "axs.set_yscale('log')\n",
    "axs.set_ylim([1E-6,1E2])\n",
    "axs.set_ylabel(r\"$|\\nabla_{\\theta}L|$\",fontsize=22)\n",
    "axs.set_xlabel(r\"$epochs$\",fontsize=22)\n",
    "axs.tick_params(axis='both', which='major', labelsize=16)\n",
    "#axs.legend(fontsize=18, frameon=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/fig/FINAL/1_RD Weights_Limit_grad.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lambda max vs epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grad analysis\n",
    "fig, axs=plt.subplots(1,1, figsize=(7,5),sharex=True)\n",
    "axs.spines[\"right\"].set_color(\"none\")\n",
    "axs.spines[\"top\"].set_color(\"none\")\n",
    "\n",
    "plot_logs_trainings(tanhpos_n100_nle10_Exploding,'training_lambda_max', axs, r'$\\lambda_{target}:10$', color='green')\n",
    "plot_logs_trainings(tanhpos_n100_nle10,'training_lambda_max', axs, r'$\\lambda_{target}:0$', color='red')\n",
    "plot_logs_trainings(tanhpos_n100_nle10_Vanishing,'training_lambda_max', axs, r'$\\lambda_{target}:-2$', color='blue')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "axs.set_xlim([0,100])\n",
    "#axs.set_yscale('log')\n",
    "axs.set_ylabel(r\"$\\lambda_{max}$\",fontsize=20)\n",
    "axs.set_xlabel(r\"$epochs$\",fontsize=20)\n",
    "axs.tick_params(axis='both', which='major', labelsize=16)\n",
    "#axs.legend(fontsize=12,loc='lower right', frameon=False)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grad analysis\n",
    "fig, axs=plt.subplots(1,1, figsize=(7,5),sharex=True)\n",
    "axs.spines[\"right\"].set_color(\"none\")\n",
    "axs.spines[\"top\"].set_color(\"none\")\n",
    "\n",
    "plot_logs_trainings(tanhpos_n100_nle10_Exploding,'spectrum', axs, r'$\\lambda_{target}:\\vec{2}$', color='green')\n",
    "plot_logs_trainings(tanhpos_n100_nle10,'spectrum', axs, r'$\\lambda_{target}:\\vec{0}$', color='red')\n",
    "plot_logs_trainings(tanhpos_n100_nle10_Vanishing,'spectrum', axs, r'$\\lambda_{target}:\\vec{-2}$', color='blue')\n",
    "\n",
    "\n",
    "axs.set_xlim([0,100])\n",
    "axs.hlines(y=0,xmin=0, xmax=100, ls='--', color='black' ,lw=2, alpha=0.5)\n",
    "axs.set_ylabel(r\"$\\lambda_{i}$\",fontsize=22)\n",
    "axs.set_xlabel(r\"$i$\",fontsize=22)\n",
    "axs.tick_params(axis='both', which='major', labelsize=16)\n",
    "axs.legend(fontsize=20, loc='upper right',frameon=False)\n",
    "axs.set_ylim(-3,2.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/fig/FINAL/1_RD Weights_Limit_spect.svg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Plot the convergence as function of the number of lyapu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_conv_grad_based(list_of_logs, window_size=100):\n",
    "    grad_weigths=np.zeros((len(list_of_logs),len(list_of_logs[0]['grad_weights'])))\n",
    "    grad_shifts=np.zeros((len(list_of_logs),len(list_of_logs[0]['grad_shifts'])))\n",
    "    grad_gains=np.zeros((len(list_of_logs),len(list_of_logs[0]['grad_gains'])))\n",
    "\n",
    "    for i, sample in enumerate(list_of_logs):\n",
    "        grad_weigths[i, :]=np.array(sample['grad_weights'])\n",
    "        grad_shifts[i, :]=np.array(sample['grad_shifts'])\n",
    "        grad_gains[i, :]=np.array(sample['grad_gains'])\n",
    "        #plt.plot(np.arange(100),grad_shifts[i, -100:])\n",
    "\n",
    "    mean_weight=np.mean(grad_weigths[:, -window_size:], axis=1)\n",
    "    mean_shifts=np.mean(grad_shifts[:, -window_size:], axis=1)\n",
    "    mean_gains=np.mean(grad_gains[:, -window_size:], axis=1)\n",
    "    \n",
    "    return {'weights':mean_weight,\n",
    "            'gains':mean_gains,\n",
    "            'shifts':mean_shifts}\n",
    "\n",
    "def compute_conv_loss_based(list_of_logs, window_size=100):\n",
    "    loss=np.zeros((len(list_of_logs),len(list_of_logs[0]['training_loss'])))\n",
    "\n",
    "    for i, sample in enumerate(list_of_logs):\n",
    "        loss[i, :]=np.array(sample['training_loss'])\n",
    "        #plt.plot(np.arange(100),grad_shifts[i, -100:])\n",
    "\n",
    "    mean_loss=np.mean(loss[:, -window_size:], axis=1)\n",
    "    return {'loss':mean_loss}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_conv_grad_based(expriment_lists, experiment_names,ax):\n",
    "    # Prepare data for plotting\n",
    "    data = []\n",
    "    for exp, label in zip(expriment_lists, experiment_names):\n",
    "        dict_conv =compute_conv_grad_based(exp)\n",
    "        combined_values = dict_conv['weights']  # Combine gains and shifts\n",
    "        for value in combined_values:\n",
    "            data.append({'Experiment': label, 'Value': value})\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "  \n",
    "    # Calculate means and error bars (standard deviation or standard error)\n",
    "    summary = df.groupby('Experiment')['Value'].agg(['mean', 'std', 'min', 'max']).reset_index()\n",
    "    summary['x'] = range(1, len(summary) + 1)\n",
    "    # Plot using matplotlib\n",
    "    \n",
    "    # Combine upper and lower errors\n",
    "    yerr = [summary['min'], summary['max']]\n",
    "\n",
    "    # Plot line and error bars with the adjusted errors\n",
    "    ax.scatter(df['Experiment'], df['Value'],color='#3759FF', alpha=0.4,label='Runs')\n",
    "    ax.plot(summary['Experiment'], summary['mean'], color='black',marker='d',markersize=8, alpha=0.6, label='Mean')\n",
    "    #ax.errorbar(summary['Experiment']-3, summary['mean'], yerr=yerr, fmt='None', markersize=8, \n",
    "    #             capsize=4, alpha=0.6)\n",
    "    # Customize the plot\n",
    "    ax.spines[\"right\"].set_color(\"none\")\n",
    "    ax.spines[\"top\"].set_color(\"none\")\n",
    "    ax.set_xticks(summary['Experiment'])\n",
    "    ax.set_xticklabels(summary['Experiment'], fontsize=12)\n",
    "    \n",
    "   \n",
    "\n",
    "def plot_conv_loss_based(expriment_lists, experiment_names,ax):\n",
    "    # Prepare data for plotting\n",
    "    data = []\n",
    "    for exp, label in zip(expriment_lists, experiment_names):\n",
    "        dict_conv =compute_conv_loss_based(exp)\n",
    "        combined_values=dict_conv['loss'] # Combine gains and shifts\n",
    "        for value in combined_values:\n",
    "            data.append({'Experiment': label, 'Value': value})\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "  \n",
    "    # Calculate means and error bars (standard deviation or standard error)\n",
    "    summary = df.groupby('Experiment')['Value'].agg(['mean', 'std', 'min', 'max']).reset_index()\n",
    "    summary['x'] = range(1, len(summary) + 1)\n",
    "    # Plot using matplotlib\n",
    "    \n",
    "    # Combine upper and lower errors\n",
    "    yerr = [summary['min'], summary['max']]\n",
    "\n",
    "    # Plot line and error bars with the adjusted errors\n",
    "    ax.scatter(df['Experiment'], df['Value'],color='#3759FF', alpha=0.4,label='Runs')\n",
    "    ax.plot(summary['Experiment'], summary['mean'], color='black',marker='d',markersize=8, alpha=0.6, label='Mean')\n",
    "    #ax.errorbar(summary['Experiment']-3, summary['mean'], yerr=yerr, fmt='None', markersize=8, \n",
    "    #             capsize=4, alpha=0.6)\n",
    "    # Customize the plot\n",
    "    ax.spines[\"right\"].set_color(\"none\")\n",
    "    ax.spines[\"top\"].set_color(\"none\")\n",
    "    ax.set_xticks(summary['Experiment'])\n",
    "    ax.set_xticklabels(summary['Experiment'], fontsize=12)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(1,1, figsize=(7,5),sharex=True)\n",
    "ax.spines[\"right\"].set_color(\"none\")\n",
    "ax.spines[\"top\"].set_color(\"none\")\n",
    "\n",
    "experiment_labels = [1, 10, 25, 50, 75, 100]\n",
    "plot_conv_loss_based(exp_nle,experiment_labels,ax)\n",
    "\n",
    "ax.set_ylabel(r\"$\\frac{1}{N} \\sum_{T-50}^{T}L_{\\theta}^t$\", fontsize=14)\n",
    "ax.set_xlabel(\"Number of Lyapunov exponent\", fontsize=20)\n",
    "ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "ax.set_yscale('log')\n",
    "ax.legend(loc='lower right',fontsize=16, frameon=False)\n",
    "ax.set_ylim([1E-15, 1E0])\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/fig/FINAL/1_RD_Weights_NLE_convergence_loss_based.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(1,1, figsize=(7,5),sharex=True)\n",
    "ax.spines[\"right\"].set_color(\"none\")\n",
    "ax.spines[\"top\"].set_color(\"none\")\n",
    "\n",
    "experiment_labels = [1, 10, 25, 50, 75, 100]\n",
    "plot_conv_grad_based(exp_nle,experiment_labels,ax)\n",
    "\n",
    "ax.set_ylabel(r\"$|\\nabla L_{\\theta}|$\", fontsize=20)\n",
    "ax.set_xlabel(\"Number of Lyapunov exponent\", fontsize=20)\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "ax.set_yscale('log')\n",
    "ax.legend(loc='lower right',fontsize=12, frameon=False)\n",
    "ax.set_ylim([1E-9, 1E0])\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/fig/FINAL/1_RD_Weights_NLE_convergence_grad_based.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Plot the convergence as function of the net size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(1,1, figsize=(7,5),sharex=True)\n",
    "ax.spines[\"right\"].set_color(\"none\")\n",
    "ax.spines[\"top\"].set_color(\"none\")\n",
    "\n",
    "experiment_labels = [25, 50, 100, 200, 400,500]\n",
    "plot_conv_loss_based(exp_n,experiment_labels,ax)\n",
    "\n",
    "ax.set_ylabel(r\"$\\frac{1}{N} \\sum_{T-50}^{T}L_{\\theta}^t$\", fontsize=20)\n",
    "ax.set_xlabel(\"Network size\", fontsize=20)\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylim([1E-9, 1E0])\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/fig/FINAL/1_RD_Weights_N_convergence_loss_based.svg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(1,1, figsize=(7,5),sharex=True)\n",
    "ax.spines[\"right\"].set_color(\"none\")\n",
    "ax.spines[\"top\"].set_color(\"none\")\n",
    "\n",
    "experiment_labels = [25, 50, 100, 200, 400,500]\n",
    "plot_conv_grad_based(exp_n,experiment_labels,ax)\n",
    "\n",
    "ax.set_ylabel(r\"$|\\nabla L_{\\theta}|$\", fontsize=20)\n",
    "ax.set_xlabel(\"Network size\", fontsize=20)\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylim([1E-9, 1E0])\n",
    "ax.set_ylim([0, 0.25])\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/fig/FINAL/1_RD_Weights_N_convergence_grad_based.svg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Plot the time of compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time(expriment_lists, experiment_names,ax):\n",
    "    # Prepare data for plotting\n",
    "    data = []\n",
    "    for exp, label in zip(expriment_lists, experiment_names):\n",
    "        time=[]\n",
    "        for run in exp:\n",
    "            time.append(float(run['time_training'])/400)\n",
    "        combined_values = time\n",
    "        for value in combined_values:\n",
    "            data.append({'Experiment': label, 'Value': value})\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Calculate means and error bars (standard deviation or standard error)\n",
    "    summary = df.groupby('Experiment')['Value'].agg(['mean', 'std']).reset_index()\n",
    "    summary['x'] = range(1, len(summary) + 1)\n",
    "    # Plot using matplotlib\n",
    "    print(summary)\n",
    "    #ax.scatter(df['Experiment'], df['Value'], color='black', alpha=0.2)\n",
    "    ax.plot(summary['Experiment'], summary['mean'], color='blue',alpha=0.4)\n",
    "    ax.errorbar(summary['Experiment'], summary['mean'], yerr=summary['std'], fmt='o', markersize=10, lw=1,capsize=4, label='Error (std)', alpha=0.4, color='blue')\n",
    "    \n",
    "    # Customize the plot\n",
    "    ax.spines[\"right\"].set_color(\"none\")\n",
    "    ax.spines[\"top\"].set_color(\"none\")\n",
    "    ax.set_xticks(summary['Experiment'])\n",
    "    ax.set_xticklabels(summary['Experiment'], fontsize=16)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(1,1, figsize=(7,5),sharex=True)\n",
    "ax.spines[\"right\"].set_color(\"none\")\n",
    "ax.spines[\"top\"].set_color(\"none\")\n",
    "\n",
    "ax.set_ylabel(r\"Computation time $[\\frac{s}{epoch}]$\", fontsize=20)\n",
    "ax.set_xlabel(\"Number of lyapunov exponent\", fontsize=20)\n",
    "\n",
    "experiment_labels = [1, 10, 25, 50, 75, 100]\n",
    "plot_time(exp_nle,experiment_labels,ax)\n",
    "plt.savefig('../data/fig/FINAL/1_RD_Weights_Nle_Effi.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(1,1, figsize=(7,5),sharex=True)\n",
    "ax.spines[\"right\"].set_color(\"none\")\n",
    "ax.spines[\"top\"].set_color(\"none\")\n",
    "\n",
    "ax.set_ylabel(r\"Computation time $[\\frac{s}{epoch}]$\", fontsize=20)\n",
    "ax.set_xlabel(\"Network size\", fontsize=20)\n",
    "\n",
    "experiment_labels = [25, 50, 100, 200, 400,500]\n",
    "plot_time(exp_n,experiment_labels,ax)\n",
    "plt.savefig('../data/fig/FINAL/1_RD_Weights_N_Effi.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Weights distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_path( subfolder:str,\n",
    "                    activation:str, \n",
    "                     weights=True, \n",
    "                     shifts=False, \n",
    "                     gains=False,\n",
    "                     nSamples=0,\n",
    "                     Nle=10,\n",
    "                     Epochs=400,\n",
    "                     lr=0.01 ,\n",
    "                     loss='MSE',\n",
    "                     target='0.00',\n",
    "                     tons=0.2,\n",
    "                     tsim=200,\n",
    "                     dt=0.1):\n",
    "    data=[]\n",
    "    gen_path=os.path.join(utils.get_root(), 'data', 'models',subfolder,'weigth') \n",
    "    model_path=f\"{activation}_Weights{weights}_Shifts{shifts}_Gains{gains}_N100_lr{lr}_NLE{Nle}_Epochs{Epochs}_{loss}_{target}_g1.0_Tons{tons}_Tsim{tsim}_dt{dt}_Sample{nSamples}\"\n",
    "    return os.path.join(gen_path, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_weight_dist(model, ax, serie_name='', color='red', alpha=0.3):\n",
    "    \"\"\"\n",
    "    Plot the weight distribution of a model on the provided axes.\n",
    "\n",
    "    Parameters:\n",
    "        model: The model object with weight attributes.\n",
    "        ax: The Matplotlib Axes object to plot on.\n",
    "        serie_name: Label for the legend.\n",
    "        color: Color for the distribution plot.\n",
    "        alpha: Transparency level for the plot.\n",
    "    \"\"\"\n",
    "    array_weight = model.W.view(-1)\n",
    "    sns.kdeplot(array_weight, ax=ax, label=serie_name, color=color, alpha=alpha)\n",
    "    ax.set_title('Synpatic coupling distribution')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nle10_1=model.RNN(get_model_path(subfolder='rd_RNN',activation='tanh_positive', Nle=10,nSamples=0),'pos' )\n",
    "nle10_2=model.RNN(get_model_path(subfolder='rd_RNN',activation='tanh_positive', Nle=10,nSamples=1),'pos' )\n",
    "nle10_3=model.RNN(get_model_path(subfolder='rd_RNN',activation='tanh_positive', Nle=10,nSamples=2),'pos' )\n",
    "nle10_4=model.RNN(get_model_path(subfolder='rd_RNN',activation='tanh_positive', Nle=10,nSamples=3),'pos' )\n",
    "\n",
    "nle50_1=model.RNN(get_model_path(subfolder='rd_RNN',activation='tanh_positive', Nle=50,nSamples=0),'pos' )\n",
    "nle50_2=model.RNN(get_model_path(subfolder='rd_RNN',activation='tanh_positive', Nle=50,nSamples=1),'pos' )\n",
    "nle50_3=model.RNN(get_model_path(subfolder='rd_RNN',activation='tanh_positive', Nle=50,nSamples=2),'pos' )\n",
    "nle50_4=model.RNN(get_model_path(subfolder='rd_RNN',activation='tanh_positive', Nle=50,nSamples=3),'pos' )\n",
    "\n",
    "\n",
    "nle75_1=model.RNN(get_model_path(subfolder='rd_RNN',activation='tanh_positive', Nle=75,nSamples=0),'pos' )\n",
    "nle75_2=model.RNN(get_model_path(subfolder='rd_RNN',activation='tanh_positive', Nle=75,nSamples=1),'pos' )\n",
    "nle75_3=model.RNN(get_model_path(subfolder='rd_RNN',activation='tanh_positive', Nle=75,nSamples=2),'pos' )\n",
    "nle75_4=model.RNN(get_model_path(subfolder='rd_RNN',activation='tanh_positive', Nle=75,nSamples=3),'pos' )\n",
    "\n",
    "# Define models and their colors\n",
    "model_groups = {\n",
    "    'NLE=10': {'models': [nle10_1, nle10_2, nle10_3, nle10_4], 'color': 'red'},\n",
    "    'NLE=50': {'models': [nle50_1, nle50_2, nle50_3, nle50_4], 'color': 'blue'},\n",
    "    'NLE=75': {'models': [nle75_1, nle75_2, nle75_3, nle75_4], 'color': 'orange'},\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the figure\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 4))\n",
    "# Plot distributions for each group\n",
    "for label, group in model_groups.items():\n",
    "    for idx, model in enumerate(group['models']):\n",
    "        # Add series name only for the last model in each group\n",
    "        serie_name = label if idx == len(group['models']) - 1 else ''\n",
    "        plot_weight_dist(model, ax, serie_name=serie_name, color=group['color'])\n",
    "\n",
    "# Display the legend\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flybrain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
